% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Movielens Capstone Project},
  pdfauthor={Philip Kassel},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\title{Movielens Capstone Project}
\author{Philip Kassel}
\date{4/26/2021}

\begin{document}
\maketitle

\hypertarget{introduction}{%
\subsection{Introduction}\label{introduction}}

The purpose of this project is to improve upon the techniques described
in the Movie Recommendations section of the textbook
\href{https://www.routledge.com/Introduction-to-Data-Science-Data-Analysis-and-Prediction-Algorithms-with/Irizarry/p/book/9780367357986}{Introduction
to Data Science}. Using actual moving ratings from the
\href{https://grouplens.org/datasets/movielens/}{MovieLens 10M Dataset},
we want to design an algorithm that can predict the ratings that
specific users will give to specific movies. To prevent overtraining of
our model, the MovieLens data set will be split into two groups: a
training set which is used to train and optimize our model and a
validation set.

The training set contains approximately 9 million ratings and the
validation set contains approximately 1 million. Both the training set
and the validation set contain the actual ratings that were given to
movies by specific users. The validation set, however, contains
movie/user combinations that have not been seen by our model before. We
can therefore compare our predicted ratings in the validation set to the
true ratings in order to measure how well our model performs.

To measure the performance of our model, we will calculate the residual
mean squared error (RMSE) of our predictions. RMSE can be interpreted as
the average error we make when predicting a rating. The smaller the
number, the better our model performs. If the RMSE is larger than 1, it
means that the average prediction is more than 1 star away from the true
rating, which is not good. For this project, we will aim to achieve an
RMSE less than 0.86490.

\hypertarget{preparing-the-data}{%
\subsection{Preparing the Data}\label{preparing-the-data}}

Exploring the MovieLens dataset reveals that the following rating
attributes can be used to train our model: the user that gave the
rating, the movie that was rated, the true rating that was given, the
timestamp of when the rating occurred, and the genres that were assigned
to the rated movie.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{edx[}\KeywordTok{sample}\NormalTok{(.N, }\DecValTok{5}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    userId movieId rating  timestamp                            title
## 1:  50805    1095    4.0  952366935       Glengarry Glen Ross (1992)
## 2:  42011    6303    3.5 1121891132     Andromeda Strain, The (1971)
## 3:  45985     593    4.0  854490846 Silence of the Lambs, The (1991)
## 4:  19660    4210    4.0 1207988321                 Manhunter (1986)
## 5:  46073     186    4.0 1123689113               Nine Months (1995)
##                                genres
## 1:                              Drama
## 2:                     Mystery|Sci-Fi
## 3:              Crime|Horror|Thriller
## 4: Action|Crime|Drama|Horror|Thriller
## 5:                     Comedy|Romance
\end{verbatim}

Included in the title of each rated movie is the year that the movie was
released, which we will extract because it might be a useful predictor.
We will also measure the length of time between each movie's release
date and when each rating occurred, rounded the nearest 5 year
increment.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{edx}\OperatorTok{$}\NormalTok{release_year <-}\StringTok{ }\KeywordTok{str_sub}\NormalTok{(edx}\OperatorTok{$}\NormalTok{title,}\DataTypeTok{start=} \DecValTok{-6}\NormalTok{)}
\NormalTok{edx}\OperatorTok{$}\NormalTok{release_year <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{str_extract}\NormalTok{(edx}\OperatorTok{$}\NormalTok{release_year, }\StringTok{"}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{d+"}\NormalTok{))}
\NormalTok{edx}\OperatorTok{$}\NormalTok{rating_year <-}\StringTok{ }\KeywordTok{year}\NormalTok{(}\KeywordTok{as.Date}\NormalTok{(}\KeywordTok{as.POSIXct}\NormalTok{(edx}\OperatorTok{$}\NormalTok{timestamp,}\DataTypeTok{origin=}\StringTok{"1970-01-01"}\NormalTok{)))}
\NormalTok{edx}\OperatorTok{$}\NormalTok{years_since_release <-}\StringTok{ }\KeywordTok{round}\NormalTok{((edx}\OperatorTok{$}\NormalTok{rating_year }\OperatorTok{-}\StringTok{ }\NormalTok{edx}\OperatorTok{$}\NormalTok{release_year) }\OperatorTok{/}\StringTok{ }\DecValTok{5}\NormalTok{) }\OperatorTok{*}\StringTok{ }\DecValTok{5}

\NormalTok{validation}\OperatorTok{$}\NormalTok{release_year <-}\StringTok{ }\KeywordTok{str_sub}\NormalTok{(validation}\OperatorTok{$}\NormalTok{title,}\DataTypeTok{start=} \DecValTok{-6}\NormalTok{)}
\NormalTok{validation}\OperatorTok{$}\NormalTok{release_year <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{str_extract}\NormalTok{(validation}\OperatorTok{$}\NormalTok{release_year, }\StringTok{"}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{d+"}\NormalTok{))}
\NormalTok{validation}\OperatorTok{$}\NormalTok{rating_year <-}\StringTok{ }\KeywordTok{year}\NormalTok{(}\KeywordTok{as.Date}\NormalTok{(}\KeywordTok{as.POSIXct}\NormalTok{(validation}\OperatorTok{$}\NormalTok{timestamp,}\DataTypeTok{origin=}\StringTok{"1970-01-01"}\NormalTok{)))}
\CommentTok{# Round to the nearest 10 year increment}
\NormalTok{validation}\OperatorTok{$}\NormalTok{years_since_release <-}\StringTok{ }\KeywordTok{round}\NormalTok{((validation}\OperatorTok{$}\NormalTok{rating_year }\OperatorTok{-}\StringTok{ }\NormalTok{validation}\OperatorTok{$}\NormalTok{release_year) }\OperatorTok{/}\StringTok{ }\DecValTok{5}\NormalTok{) }\OperatorTok{*}\StringTok{ }\DecValTok{5}

\NormalTok{edx[}\KeywordTok{sample}\NormalTok{(.N, }\DecValTok{5}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    userId movieId rating  timestamp
## 1:  13268     490    4.0  923662715
## 2:   6910     720    0.5 1190501372
## 3:  30265    2408    2.0  974969711
## 4:  65174     930    3.5 1159822942
## 5:  18227    6240    5.0 1050522610
##                                                     title
## 1:                                          Malice (1993)
## 2: Wallace & Gromit: The Best of Aardman Animation (1996)
## 3:                              Cocoon: The Return (1988)
## 4:                                       Notorious (1946)
## 5:                                    One Good Cop (1991)
##                        genres release_year rating_year years_since_release
## 1:                   Thriller         1993        1999                   5
## 2: Adventure|Animation|Comedy         1996        2007                  10
## 3:              Comedy|Sci-Fi         1988        2000                  10
## 4: Film-Noir|Romance|Thriller         1946        2006                  60
## 5:         Action|Crime|Drama         1991        2003                  10
\end{verbatim}

\hypertarget{techniques}{%
\subsection{Techniques}\label{techniques}}

To train our model, we will first establish a baseline, \emph{mu}, which
is simply the average rating given in our training set. We will then
build on this baseline by exploring how the following effects can
influence a specific user's rating of a movie: The movie itself, the
user that rated the movie, the user's genre preferences, and the time
that elapsed between the release of the movie and when the rating was
given.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mu <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(edx}\OperatorTok{$}\NormalTok{rating)}
\KeywordTok{paste}\NormalTok{(}\StringTok{"Average Movie Rating:"}\NormalTok{, }\KeywordTok{round}\NormalTok{(mu, }\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Average Movie Rating: 3.512"
\end{verbatim}

\hypertarget{movie-effect}{%
\subsubsection{Movie Effect}\label{movie-effect}}

Now that we have our baseline, we can approximate how different effects
can influence the way that a particular rating will deviate from the
average rating. For example, we know that some movies are more highly
regarded than others, so we would expect for those movies to be rated
higher than average. Some movies are also known flops, so we would
except for those movies to be rated lower than average.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{titles <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Mars Attacks! (1996)"}\NormalTok{, }\StringTok{"Dumb and Dumberer: When Harry Met Lloyd (2003)"}\NormalTok{, }\StringTok{"Godfather, The (1972)"}\NormalTok{, }\StringTok{"Gone with the Wind (1939)"}\NormalTok{, }\StringTok{"War of the Worlds 2: The Next Wave (2008)"}\NormalTok{, }\StringTok{"Hellhounds on My Trail (1999)"}\NormalTok{)}

\NormalTok{edx }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(title }\OperatorTok{%in%}\StringTok{ }\NormalTok{titles) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{group_by}\NormalTok{(title) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{avg_movie_rating=}\KeywordTok{mean}\NormalTok{(rating)) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{arrange}\NormalTok{(avg_movie_rating) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{title =} \KeywordTok{strtrim}\NormalTok{(title, }\DecValTok{25}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(title, avg_movie_rating)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{stat=}\StringTok{"identity"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{axis.text.x =} \KeywordTok{element_text}\NormalTok{(}\DataTypeTok{angle =} \DecValTok{60}\NormalTok{, }\DataTypeTok{hjust =} \DecValTok{1}\NormalTok{)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Sample of Average Movie Ratings"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{MovieLens_files/figure-latex/unnamed-chunk-4-1.pdf}

Some of these movies we would expect to have such high or low ratings;
for example, the sequel to ``Dumb and Dumber'', ``The Godfather'', and
``Gone with the Wind''. But, is it really likely that the average user
will rate ``Hellhounds on My Trail'' higher than ``The Godfather''? As
it turns out, the less often a movie is rated, the more likely it is to
appear at the extremes of the rating spectrum. In the following visual,
we can clearly see that the movies with the highest and lowest ratings
have been rated very few times.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{edx }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(title }\OperatorTok{%in%}\StringTok{ }\NormalTok{titles) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{group_by}\NormalTok{(title) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{avg_movie_rating=}\KeywordTok{mean}\NormalTok{(rating), }\DataTypeTok{number_of_ratings =} \KeywordTok{n}\NormalTok{()) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{arrange}\NormalTok{(number_of_ratings) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(number_of_ratings, avg_movie_rating, }\DataTypeTok{color=}\NormalTok{title)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Avg Movie Rating Compared To Number of Reviews"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{MovieLens_files/figure-latex/unnamed-chunk-5-1.pdf}

Using a technique called regularization, we can apply a parameter to our
ratings, which we'll call \emph{lambda}, that will penalize underrated
movies in order to better approximate how they might deviate from our
average rating, \emph{mu}. We'll tune this parameter using
cross-validation, so that we can find the best value for \emph{lambda}
that minimizes our RMSE score. Once \emph{lambda} has been tuned, we can
calculate the movie bias by subtracting the regularized average rating
for each movie from our baseline \emph{mu}.

Since tuning our lambda parameter will require us to run our model many
times, we will use only a sample of one million records from our
training set. To prevent over training of our model (which would lead to
less accurate predictions on our validation set), we will further split
our training set: 90\% will be used to train our tuning model and the
remaining 10\% will be used to test the accuracy of our predictions. The
\emph{lambda} parameter that helps us achieve the lowest residual mean
error (RMSE) in our predictions will be the one that is used in our
final model.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{### Collect a sample of 1 million ratings from the training set end separate}
\CommentTok{### it into our training and test set}

\NormalTok{sample <-}\StringTok{ }\NormalTok{edx[}\DecValTok{1}\OperatorTok{:}\DecValTok{1000000}\NormalTok{]}
\NormalTok{ind <-}\StringTok{ }\KeywordTok{createDataPartition}\NormalTok{(sample}\OperatorTok{$}\NormalTok{rating, }\DataTypeTok{times =} \DecValTok{1}\NormalTok{, }\DataTypeTok{p=}\FloatTok{0.1}\NormalTok{, }\DataTypeTok{list=}\OtherTok{FALSE}\NormalTok{)}
\NormalTok{train_set <-}\StringTok{ }\NormalTok{sample[}\OperatorTok{-}\NormalTok{ind]}
\NormalTok{test_set <-}\StringTok{ }\NormalTok{sample[ind]}

\CommentTok{### we want to make sure that the test set only has movies and users that are in}
\CommentTok{### the train set}
\NormalTok{test_set <-}\StringTok{ }\NormalTok{test_set }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{semi_join}\NormalTok{(train_set, }\DataTypeTok{by =} \StringTok{"movieId"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{semi_join}\NormalTok{(train_set, }\DataTypeTok{by =} \StringTok{"userId"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{semi_join}\NormalTok{(train_set, }\DataTypeTok{by =} \StringTok{"years_since_release"}\NormalTok{)}


\NormalTok{mu <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(train_set}\OperatorTok{$}\NormalTok{rating)}
\NormalTok{lambdas <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{20}\NormalTok{,.}\DecValTok{5}\NormalTok{)}

\NormalTok{tune_lambdas <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(grouping) \{}
  \ControlFlowTok{if}\NormalTok{ (grouping }\OperatorTok{==}\StringTok{ "genre"}\NormalTok{) \{}
\NormalTok{    biases <-}\StringTok{ }\NormalTok{genre_ratings_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{group_by}\NormalTok{(userId, genres)}
\NormalTok{  \}}

  \ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    biases <-}\StringTok{ }\NormalTok{train_set }\OperatorTok{%>%}\StringTok{ }\KeywordTok{group_by}\NormalTok{(}\OperatorTok{!!}\KeywordTok{as.symbol}\NormalTok{(grouping))}
\NormalTok{  \}}
\NormalTok{  rate_lambda <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(lambda) \{}
    \ControlFlowTok{if}\NormalTok{ (grouping }\OperatorTok{==}\StringTok{ "genre"}\NormalTok{) \{}
\NormalTok{      temp <-}\StringTok{ }\NormalTok{biases }\OperatorTok{%>%}\StringTok{ }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{genre_bias =} \KeywordTok{sum}\NormalTok{(rating }\OperatorTok{-}\StringTok{ }\NormalTok{movie_bias }\OperatorTok{-}\StringTok{ }\NormalTok{user_bias }\OperatorTok{-}\StringTok{ }\NormalTok{mu)}\OperatorTok{/}\NormalTok{(}\KeywordTok{n}\NormalTok{() }\OperatorTok{+}\StringTok{ }\NormalTok{lambda))}
\NormalTok{      temp <-}\StringTok{ }\NormalTok{temp }\OperatorTok{%>%}\StringTok{ }\KeywordTok{inner_join}\NormalTok{(test_genre_ratings_df, }\DataTypeTok{on=}\NormalTok{genres)}
\NormalTok{      predictions <-}\StringTok{ }\NormalTok{temp }\OperatorTok{%>%}\StringTok{ }
\StringTok{        }\KeywordTok{left_join}\NormalTok{(movies_df, }\DataTypeTok{on=}\StringTok{"movieId"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{left_join}\NormalTok{(users_df, }\DataTypeTok{on=}\StringTok{"userId"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{        }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pred=}\NormalTok{mu }\OperatorTok{+}\StringTok{ }\NormalTok{genre_bias }\OperatorTok{+}\StringTok{ }\NormalTok{movie_bias }\OperatorTok{+}\StringTok{ }\NormalTok{user_bias)}
\NormalTok{    \}}
    \ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (grouping }\OperatorTok{==}\StringTok{ "userId"}\NormalTok{) \{}
\NormalTok{      temp <-}\StringTok{ }\NormalTok{biases }\OperatorTok{%>%}\StringTok{ }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{user_bias =} \KeywordTok{sum}\NormalTok{(rating }\OperatorTok{-}\StringTok{ }\NormalTok{movie_bias }\OperatorTok{-}\StringTok{ }\NormalTok{mu)}\OperatorTok{/}\NormalTok{(}\KeywordTok{n}\NormalTok{() }\OperatorTok{+}\StringTok{ }\NormalTok{lambda))}
\NormalTok{      predictions <-}\StringTok{ }\NormalTok{test_set }\OperatorTok{%>%}\StringTok{ }\KeywordTok{inner_join}\NormalTok{(temp, }\DataTypeTok{on=}\OperatorTok{!!}\KeywordTok{as.symbol}\NormalTok{(grouping)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{        }\KeywordTok{left_join}\NormalTok{(movies_df, }\DataTypeTok{on=}\NormalTok{movieId) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pred =}\NormalTok{ mu }\OperatorTok{+}\StringTok{ }\NormalTok{movie_bias }\OperatorTok{+}\StringTok{ }\NormalTok{user_bias) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(rating, pred)}
\NormalTok{    \}}
    \ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (grouping }\OperatorTok{==}\StringTok{ "years_since_release"}\NormalTok{) \{}
\NormalTok{      ug <-}\StringTok{ }\NormalTok{user_genres_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{movieId) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{group_by}\NormalTok{(userId, genres) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{genre_bias =} \KeywordTok{mean}\NormalTok{(genre_bias))}
\NormalTok{      tg <-}\StringTok{ }\NormalTok{test_genre_ratings_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{inner_join}\NormalTok{(ug, }\DataTypeTok{on=}\NormalTok{genres) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{group_by}\NormalTok{(userId, movieId) }\OperatorTok{%>%}\StringTok{ }
\StringTok{        }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{user_genre_bias =} \KeywordTok{mean}\NormalTok{(genre_bias))}
\NormalTok{      temp <-}\StringTok{ }\NormalTok{biases }\OperatorTok{%>%}\StringTok{ }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{bias=}\KeywordTok{sum}\NormalTok{(rating }\OperatorTok{-}\StringTok{ }\NormalTok{mu }\OperatorTok{-}\StringTok{ }\NormalTok{movie_bias }\OperatorTok{-}\StringTok{ }\NormalTok{user_bias }\OperatorTok{-}\StringTok{ }\NormalTok{user_genre_bias) }\OperatorTok{/}\StringTok{ }\NormalTok{(}\KeywordTok{n}\NormalTok{() }\OperatorTok{+}\StringTok{ }\NormalTok{lambda))}

\NormalTok{      predictions <-}\StringTok{ }\NormalTok{test_set }\OperatorTok{%>%}\StringTok{ }\KeywordTok{left_join}\NormalTok{(temp, }\DataTypeTok{on=}\NormalTok{years_since_release) }\OperatorTok{%>%}\StringTok{ }
\StringTok{        }\KeywordTok{left_join}\NormalTok{(movies_df, }\DataTypeTok{on=}\NormalTok{movieId) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{left_join}\NormalTok{(users_df, }\DataTypeTok{on=}\NormalTok{userId) }\OperatorTok{%>%}
\StringTok{        }\KeywordTok{left_join}\NormalTok{(tg, }\DataTypeTok{on=}\KeywordTok{c}\NormalTok{(userId, movieId))}
\NormalTok{      predictions[}\KeywordTok{is.na}\NormalTok{(predictions)] =}\StringTok{ }\DecValTok{0}
\NormalTok{      predictions <-}\StringTok{ }\NormalTok{predictions }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pred =}\NormalTok{ mu }\OperatorTok{+}\StringTok{ }\NormalTok{movie_bias }\OperatorTok{+}\StringTok{ }\NormalTok{user_bias }\OperatorTok{+}\StringTok{ }\NormalTok{user_genre_bias }\OperatorTok{+}\StringTok{ }\NormalTok{bias)}
\NormalTok{    \}}
    \ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    temp <-}\StringTok{ }\NormalTok{biases }\OperatorTok{%>%}\StringTok{ }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{bias=}\KeywordTok{sum}\NormalTok{(rating }\OperatorTok{-}\StringTok{ }\NormalTok{mu) }\OperatorTok{/}\StringTok{ }\NormalTok{(}\KeywordTok{n}\NormalTok{() }\OperatorTok{+}\StringTok{ }\NormalTok{lambda))}
\NormalTok{    predictions <-}\StringTok{ }\NormalTok{test_set }\OperatorTok{%>%}\StringTok{ }\KeywordTok{inner_join}\NormalTok{(temp, }\DataTypeTok{on=}\OperatorTok{!!}\KeywordTok{as.symbol}\NormalTok{(grouping)) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pred =}\NormalTok{ mu }\OperatorTok{+}\StringTok{ }\NormalTok{bias) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(rating, pred)}
\NormalTok{    \}}
  \KeywordTok{RMSE}\NormalTok{(predictions}\OperatorTok{$}\NormalTok{rating, predictions}\OperatorTok{$}\NormalTok{pred)}
\NormalTok{  \}}
  \KeywordTok{sapply}\NormalTok{(lambdas, }\DataTypeTok{FUN =} \ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{rate_lambda}\NormalTok{(x))}
\NormalTok{\}}

\NormalTok{movies_lambda <-}\StringTok{ }\KeywordTok{tune_lambdas}\NormalTok{(}\StringTok{"movieId"}\NormalTok{)}
\NormalTok{movies_df <-}\StringTok{ }\NormalTok{train_set }\OperatorTok{%>%}\StringTok{ }\KeywordTok{group_by}\NormalTok{(movieId) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{movie_bias=}\KeywordTok{sum}\NormalTok{(rating }\OperatorTok{-}\StringTok{ }\NormalTok{mu)}\OperatorTok{/}\NormalTok{(}\KeywordTok{n}\NormalTok{() }\OperatorTok{+}\StringTok{ }\NormalTok{lambdas[}\KeywordTok{which.min}\NormalTok{(movies_lambda)] )) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(movieId, movie_bias)}
\NormalTok{train_set <-}\StringTok{ }\NormalTok{train_set }\OperatorTok{%>%}\StringTok{ }\KeywordTok{inner_join}\NormalTok{(movies_df, }\DataTypeTok{on=}\StringTok{"movieId"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{rmses=}\NormalTok{movies_lambda, }\DataTypeTok{lambdas =}\NormalTok{ lambdas) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(lambdas, rmses)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{ggtitle}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"Best RMSE:"}\NormalTok{, }\KeywordTok{round}\NormalTok{(}\KeywordTok{min}\NormalTok{(movies_lambda),}\DecValTok{6}\NormalTok{), }\StringTok{" | Best Lambda:"}\NormalTok{, lambdas[}\KeywordTok{which.min}\NormalTok{(movies_lambda)]))}
\end{Highlighting}
\end{Shaded}

\includegraphics{MovieLens_files/figure-latex/unnamed-chunk-7-1.pdf}

In order to make predictions about how a user might rate an unseen
movie, we can simply add the calculated \emph{movie\_bias} to our
baseline average \emph{mu} like so: \emph{predicted rating = movie\_bias
+ mu}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_set[}\KeywordTok{sample}\NormalTok{(.N, }\DecValTok{5}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{inner_join}\NormalTok{(movies_df, }\DataTypeTok{on=}\NormalTok{movieId) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(title, movie_bias) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{mu =}\NormalTok{ mu) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{predicted_rating =}\NormalTok{ movie_bias }\OperatorTok{+}\StringTok{ }\NormalTok{mu)  }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                                         title   movie_bias       mu
## 1:                          Waterworld (1995) -0.642198610 3.520253
## 2:       Thing from Another World, The (1951)  0.195889823 3.520253
## 3: Life Aquatic with Steve Zissou, The (2004)  0.004688592 3.520253
## 4:                          Jack Frost (1998) -1.176453689 3.520253
## 5:                      Mrs. Doubtfire (1993) -0.093880789 3.520253
##    predicted_rating
## 1:         2.878054
## 2:         3.716143
## 3:         3.524941
## 4:         2.343799
## 5:         3.426372
\end{verbatim}

\hypertarget{user-effects}{%
\subsubsection{User Effects}\label{user-effects}}

If not all movies are created equal, then it stands to reason that not
all users are, either. For example, Jane may be a movie buff that rates
movies more critically than John, who only watches blockbuster hits. We
can, therefore, build upon our previous \emph{movie effect}, by looking
at each user's rating for a movie and subtracting from it that movie's
\emph{movie\_bias} and our baseline \emph{mu}.

We will then use regularization and cross validation to penalize users
with fewer ratings in order to find the best value of \emph{lambda} (and
therefore calculate each user's \emph{user bias}) that minimizes RMSE.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{users_lambda <-}\StringTok{ }\KeywordTok{tune_lambdas}\NormalTok{(}\StringTok{"userId"}\NormalTok{)}
\NormalTok{users_df <-}\StringTok{ }\NormalTok{train_set }\OperatorTok{%>%}\StringTok{ }\KeywordTok{group_by}\NormalTok{(userId) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{user_bias=}\KeywordTok{sum}\NormalTok{(rating }\OperatorTok{-}\StringTok{ }\NormalTok{movie_bias }\OperatorTok{-}\StringTok{ }\NormalTok{mu)}\OperatorTok{/}\NormalTok{(}\KeywordTok{n}\NormalTok{() }\OperatorTok{+}\StringTok{ }\NormalTok{lambdas[}\KeywordTok{which.min}\NormalTok{(users_lambda)])) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(userId, user_bias)}

\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{rmses=}\NormalTok{users_lambda, }\DataTypeTok{lambdas =}\NormalTok{ lambdas) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(lambdas, rmses)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{ggtitle}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"Best RMSE:"}\NormalTok{, }\KeywordTok{round}\NormalTok{(}\KeywordTok{min}\NormalTok{(users_lambda),}\DecValTok{6}\NormalTok{), }\StringTok{" | Best Lambda:"}\NormalTok{, lambdas[}\KeywordTok{which.min}\NormalTok{(users_lambda)]))}
\end{Highlighting}
\end{Shaded}

\includegraphics{MovieLens_files/figure-latex/unnamed-chunk-9-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_set <-}\StringTok{ }\NormalTok{train_set }\OperatorTok{%>%}\StringTok{ }\KeywordTok{inner_join}\NormalTok{(users_df, }\DataTypeTok{on=}\StringTok{"userId"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Already, we can see a significant improvement in our predictions, as
measured by RMSE.

With our new approximation, we can predict how a user will rate an
unseen movie by adding their known \emph{user\_bias} to the particular
movie's known \emph{movie\_bias} and adding that to our baseline
\emph{mu}.

In other words: \emph{predicted rating = user\_bias + movie\_bias + mu}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_set[}\KeywordTok{sample}\NormalTok{(.N, }\DecValTok{5}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{inner_join}\NormalTok{(movies_df, }\DataTypeTok{on=}\NormalTok{movieId) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{inner_join}\NormalTok{(users_df, }\DataTypeTok{on=}\NormalTok{userId) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(title, movie_bias, user_bias) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{mu =}\NormalTok{ mu) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{predicted_rating =}\NormalTok{ movie_bias }\OperatorTok{+}\StringTok{ }\NormalTok{user_bias }\OperatorTok{+}\StringTok{ }\NormalTok{mu)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                                     title movie_bias  user_bias       mu
## 1:                     Toy Story 2 (1999)  0.3250506  0.2409186 3.520253
## 2:           Sense and Sensibility (1995)  0.4864494  0.2056762 3.520253
## 3:     Searching for Bobby Fischer (1993)  0.3929038  0.2294676 3.520253
## 4: Nightmare Before Christmas, The (1993)  0.1894709  0.6201546 3.520253
## 5:                          Casino (1995)  0.1748299 -0.1563618 3.520253
##    predicted_rating
## 1:         4.086222
## 2:         4.212378
## 3:         4.142624
## 4:         4.329878
## 5:         3.538721
\end{verbatim}

\hypertarget{user-genres-effect}{%
\subsubsection{User Genres Effect}\label{user-genres-effect}}

Some users prefer certain genres more than others. This effect is more
challenging to approximate because many movies can be categorized into
multiple genres.

\begin{verbatim}
##    userId movieId rating  timestamp                                title
## 1:    786     258    1.0  913064925 Kid in King Arthur's Court, A (1995)
## 2:   7289     663    3.0  853321394 Kids in the Hall: Brain Candy (1996)
## 3:   7070     208    3.0  839507492                    Waterworld (1995)
## 4:   5671     357    2.5 1169369270   Four Weddings and a Funeral (1994)
## 5:   6776     377    0.5 1190536559                         Speed (1994)
##                                       genres release_year rating_year
## 1: Adventure|Children|Comedy|Fantasy|Romance         1995        1998
## 2:                                    Comedy         1996        1997
## 3:                   Action|Adventure|Sci-Fi         1995        1996
## 4:                            Comedy|Romance         1994        2007
## 5:                   Action|Romance|Thriller         1994        2007
##    years_since_release  movie_bias  user_bias
## 1:                   5 -0.99042085 -0.1098489
## 2:                   0 -0.14863137 -0.3903074
## 3:                   0 -0.64219861 -0.3825903
## 4:                  15  0.14720162 -0.6931864
## 5:                  15 -0.03463044  0.1440741
\end{verbatim}

To measure a user's genre preferences, we will need to split each of
their ratings up by their constituent genres. Below, we can see the
sample ratings above broken down by genre.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g }\OperatorTok{%>%}\StringTok{ }\KeywordTok{separate_rows}\NormalTok{(genres, }\DataTypeTok{sep=}\StringTok{"}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{|"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(userId, rating, title, genres)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 14 x 4
##    userId rating title                                genres   
##     <int>  <dbl> <chr>                                <chr>    
##  1    786    1   Kid in King Arthur's Court, A (1995) Adventure
##  2    786    1   Kid in King Arthur's Court, A (1995) Children 
##  3    786    1   Kid in King Arthur's Court, A (1995) Comedy   
##  4    786    1   Kid in King Arthur's Court, A (1995) Fantasy  
##  5    786    1   Kid in King Arthur's Court, A (1995) Romance  
##  6   7289    3   Kids in the Hall: Brain Candy (1996) Comedy   
##  7   7070    3   Waterworld (1995)                    Action   
##  8   7070    3   Waterworld (1995)                    Adventure
##  9   7070    3   Waterworld (1995)                    Sci-Fi   
## 10   5671    2.5 Four Weddings and a Funeral (1994)   Comedy   
## 11   5671    2.5 Four Weddings and a Funeral (1994)   Romance  
## 12   6776    0.5 Speed (1994)                         Action   
## 13   6776    0.5 Speed (1994)                         Romance  
## 14   6776    0.5 Speed (1994)                         Thriller
\end{verbatim}

After this is done, we can use regularization and cross validation to
calculate a specific bias that \emph{each user has for each genre they
have rated}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{genre_ratings_df <-}\StringTok{ }\NormalTok{train_set }\OperatorTok{%>%}\StringTok{ }\KeywordTok{separate_rows}\NormalTok{(genres, }\DataTypeTok{sep=}\StringTok{"}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{|"}\NormalTok{)}
\NormalTok{test_genre_ratings_df <-}\StringTok{ }\NormalTok{test_set }\OperatorTok{%>%}\StringTok{ }\KeywordTok{separate_rows}\NormalTok{(genres, }\DataTypeTok{sep=}\StringTok{"}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{|"}\NormalTok{)}
\NormalTok{genres_lambda <-}\StringTok{ }\KeywordTok{tune_lambdas}\NormalTok{(}\StringTok{"genre"}\NormalTok{)}

\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{rmses=}\NormalTok{genres_lambda, }\DataTypeTok{lambdas =}\NormalTok{ lambdas) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(lambdas, rmses)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{ggtitle}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"Best RMSE:"}\NormalTok{, }\KeywordTok{round}\NormalTok{(}\KeywordTok{min}\NormalTok{(genres_lambda),}\DecValTok{6}\NormalTok{), }\StringTok{" | Best Lambda:"}\NormalTok{, lambdas[}\KeywordTok{which.min}\NormalTok{(genres_lambda)]))}
\end{Highlighting}
\end{Shaded}

\includegraphics{MovieLens_files/figure-latex/unnamed-chunk-13-1.pdf}

Once we have measured each user's bias for every genre, we can then
assign those genre biases to the movies in our validation set. Since one
movie may have multiple genres and each genre bias was measured
separately, we will calculate the average of all genre biases for all
movie/user/genre combinations, which we'll call
\emph{user\_genre\_bias}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{user_genres_df <-}\StringTok{ }\NormalTok{genre_ratings_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{group_by}\NormalTok{(userId, genres) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{genre_bias =} \KeywordTok{sum}\NormalTok{(rating }\OperatorTok{-}\StringTok{ }\NormalTok{movie_bias }\OperatorTok{-}\StringTok{ }\NormalTok{user_bias }\OperatorTok{-}\StringTok{ }\NormalTok{mu)}\OperatorTok{/}\NormalTok{(}\KeywordTok{n}\NormalTok{() }\OperatorTok{+}\StringTok{ }\NormalTok{lambdas[}\KeywordTok{which.min}\NormalTok{(genres_lambda)])) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{inner_join}\NormalTok{(genre_ratings_df, }\DataTypeTok{on=}\NormalTok{genres) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(userId, genres, genre_bias, movieId)}


\NormalTok{user_genres_df_wide <-}\StringTok{ }\NormalTok{user_genres_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{pivot_wider}\NormalTok{(}\DataTypeTok{names_from =}\NormalTok{ genres, }\DataTypeTok{values_from=}\NormalTok{genre_bias)}
\NormalTok{train_set <-}\StringTok{ }\NormalTok{train_set }\OperatorTok{%>%}\StringTok{ }\KeywordTok{inner_join}\NormalTok{(user_genres_df_wide, }\DataTypeTok{on=}\KeywordTok{c}\NormalTok{(}\StringTok{"userId"}\NormalTok{, }\StringTok{"movieId"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    userId rating                         title rating_year Action Adventure
## 1:   3174    3.5              Baby Mama (2008)        2008     NA        NA
## 2:   6245    2.0 Little Shop of Horrors (1986)        2001     NA        NA
## 3:   4383    4.0              Boomerang (1992)        1996     NA        NA
## 4:   5208    3.0      Conspiracy Theory (1997)        2001     NA        NA
## 5:    821    3.0       Sixth Sense, The (1999)        2005     NA        NA
##    Animation Children     Comedy Crime       Drama Fantasy   Musical    Romance
## 1:        NA       NA 0.09165471    NA          NA      NA        NA         NA
## 2:        NA       NA 0.05462930    NA          NA      NA 0.1653844         NA
## 3:        NA       NA 0.09008663    NA          NA      NA        NA  0.1197351
## 4:        NA       NA         NA    NA -0.05241881      NA        NA -0.1570873
## 5:        NA       NA         NA    NA  0.17493261      NA        NA         NA
##    Sci-Fi   Thriller War     Mystery Western Film-Noir     Horror Documentary
## 1:     NA         NA  NA          NA      NA        NA         NA          NA
## 2:     NA         NA  NA          NA      NA        NA -0.2737409          NA
## 3:     NA         NA  NA          NA      NA        NA         NA          NA
## 4:     NA  0.1055971  NA -0.21598924      NA        NA         NA          NA
## 5:     NA -0.2743949  NA -0.02007429      NA        NA         NA          NA
##    IMAX (no genres listed) user_genre_bias
## 1:   NA                 NA      0.09165471
## 2:   NA                 NA     -0.01790907
## 3:   NA                 NA      0.10491085
## 4:   NA                 NA     -0.07997456
## 5:   NA                 NA     -0.03984552
\end{verbatim}

\hypertarget{time-effect}{%
\subsubsection{Time Effect}\label{time-effect}}

When it comes to movies, there are warhorses that stand the test of
time; classics like ``Gone with the Wind'' and ``Citizen Kane''. Indeed,
we can see a fairly strong correlation between the average rating and
the length of time since a movie was released.

\begin{verbatim}
## `geom_smooth()` using method = 'loess' and formula 'y ~ x'
\end{verbatim}

\includegraphics{MovieLens_files/figure-latex/unnamed-chunk-17-1.pdf}

We can see clearly that movies are rated slightly higher than average
when they are first released and then take a dip within the first 10
years or so. After about 25 years, movies are rated increasingly rated
higher. Perhaps movies that were made longer ago are sought out
specifically because they are more critically acclaimed. No matter the
reason, this appears to be a useful predictor to include in our model.

We can also see that not every movie ages as well. Therefore, we will we
measure the effect that time can have on the average rating for every
movie in our dataset. We will call this final parameter
\emph{recency\_bias}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{edx }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(title }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Birdcage, The (1996)"}\NormalTok{, }\StringTok{"Happy Gilmore (1996)"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(years_since_release, title) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{avg_rating=}\KeywordTok{mean}\NormalTok{(rating)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(years_since_release, avg_rating, }\DataTypeTok{color=}\NormalTok{title)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_smooth}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_hline}\NormalTok{(}\DataTypeTok{yintercept=}\NormalTok{mu, }\DataTypeTok{linetype=}\StringTok{"dashed"}\NormalTok{, }\DataTypeTok{color =} \StringTok{"red"}\NormalTok{, }\DataTypeTok{size=}\NormalTok{.}\DecValTok{5}\NormalTok{) }\OperatorTok{+}\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Average Movie Rating Compared To Years Since Release"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'years_since_release'. You can override using the `.groups` argument.
\end{verbatim}

\begin{verbatim}
## `geom_smooth()` using method = 'loess' and formula 'y ~ x'
\end{verbatim}

\begin{verbatim}
## Warning in simpleLoess(y, x, w, span, degree = degree, parametric =
## parametric, : span too small. fewer data values than degrees of freedom.
\end{verbatim}

\begin{verbatim}
## Warning in simpleLoess(y, x, w, span, degree = degree, parametric =
## parametric, : pseudoinverse used at -0.075
\end{verbatim}

\begin{verbatim}
## Warning in simpleLoess(y, x, w, span, degree = degree, parametric =
## parametric, : neighborhood radius 10.075
\end{verbatim}

\begin{verbatim}
## Warning in simpleLoess(y, x, w, span, degree = degree, parametric =
## parametric, : reciprocal condition number 0
\end{verbatim}

\begin{verbatim}
## Warning in simpleLoess(y, x, w, span, degree = degree, parametric =
## parametric, : There are other near singularities as well. 101.51
\end{verbatim}

\begin{verbatim}
## Warning in predLoess(object$y, object$x, newx = if
## (is.null(newdata)) object$x else if (is.data.frame(newdata))
## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer
## data values than degrees of freedom.
\end{verbatim}

\begin{verbatim}
## Warning in predLoess(object$y, object$x, newx = if
## (is.null(newdata)) object$x else if (is.data.frame(newdata))
## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at
## -0.075
\end{verbatim}

\begin{verbatim}
## Warning in predLoess(object$y, object$x, newx = if
## (is.null(newdata)) object$x else if (is.data.frame(newdata))
## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius
## 10.075
\end{verbatim}

\begin{verbatim}
## Warning in predLoess(object$y, object$x, newx = if
## (is.null(newdata)) object$x else if (is.data.frame(newdata))
## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition
## number 0
\end{verbatim}

\begin{verbatim}
## Warning in predLoess(object$y, object$x, newx = if
## (is.null(newdata)) object$x else if (is.data.frame(newdata))
## as.matrix(model.frame(delete.response(terms(object)), : There are other near
## singularities as well. 101.51
\end{verbatim}

\begin{verbatim}
## Warning in simpleLoess(y, x, w, span, degree = degree, parametric =
## parametric, : span too small. fewer data values than degrees of freedom.
\end{verbatim}

\begin{verbatim}
## Warning in simpleLoess(y, x, w, span, degree = degree, parametric =
## parametric, : pseudoinverse used at -0.075
\end{verbatim}

\begin{verbatim}
## Warning in simpleLoess(y, x, w, span, degree = degree, parametric =
## parametric, : neighborhood radius 10.075
\end{verbatim}

\begin{verbatim}
## Warning in simpleLoess(y, x, w, span, degree = degree, parametric =
## parametric, : reciprocal condition number 0
\end{verbatim}

\begin{verbatim}
## Warning in simpleLoess(y, x, w, span, degree = degree, parametric =
## parametric, : There are other near singularities as well. 101.51
\end{verbatim}

\begin{verbatim}
## Warning in predLoess(object$y, object$x, newx = if
## (is.null(newdata)) object$x else if (is.data.frame(newdata))
## as.matrix(model.frame(delete.response(terms(object)), : span too small. fewer
## data values than degrees of freedom.
\end{verbatim}

\begin{verbatim}
## Warning in predLoess(object$y, object$x, newx = if
## (is.null(newdata)) object$x else if (is.data.frame(newdata))
## as.matrix(model.frame(delete.response(terms(object)), : pseudoinverse used at
## -0.075
\end{verbatim}

\begin{verbatim}
## Warning in predLoess(object$y, object$x, newx = if
## (is.null(newdata)) object$x else if (is.data.frame(newdata))
## as.matrix(model.frame(delete.response(terms(object)), : neighborhood radius
## 10.075
\end{verbatim}

\begin{verbatim}
## Warning in predLoess(object$y, object$x, newx = if
## (is.null(newdata)) object$x else if (is.data.frame(newdata))
## as.matrix(model.frame(delete.response(terms(object)), : reciprocal condition
## number 0
\end{verbatim}

\begin{verbatim}
## Warning in predLoess(object$y, object$x, newx = if
## (is.null(newdata)) object$x else if (is.data.frame(newdata))
## as.matrix(model.frame(delete.response(terms(object)), : There are other near
## singularities as well. 101.51
\end{verbatim}

\begin{verbatim}
## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning -
## Inf

## Warning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning -
## Inf
\end{verbatim}

\includegraphics{MovieLens_files/figure-latex/unnamed-chunk-18-1.pdf}

As we did with our previous models, we will use regularization and cross
validation to tune our penalty term \emph{lambda} to minimize our RMSE.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{years_since_release_lambda <-}\StringTok{ }\KeywordTok{tune_lambdas}\NormalTok{(}\StringTok{"years_since_release"}\NormalTok{)}
\NormalTok{recency_df <-}\StringTok{ }\NormalTok{train_set }\OperatorTok{%>%}\StringTok{ }\KeywordTok{group_by}\NormalTok{(years_since_release) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{recency_bias=}\KeywordTok{sum}\NormalTok{(rating }\OperatorTok{-}\StringTok{ }\NormalTok{movie_bias }\OperatorTok{-}\StringTok{ }\NormalTok{user_bias }\OperatorTok{-}\StringTok{ }\NormalTok{user_genre_bias }\OperatorTok{-}\StringTok{ }\NormalTok{mu)}\OperatorTok{/}\NormalTok{(}\KeywordTok{n}\NormalTok{() }\OperatorTok{+}\StringTok{ }\NormalTok{lambdas[}\KeywordTok{which.min}\NormalTok{(years_since_release_lambda)])) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(years_since_release, recency_bias)}

\NormalTok{train_set <-}\StringTok{ }\NormalTok{train_set }\OperatorTok{%>%}\StringTok{ }\KeywordTok{inner_join}\NormalTok{(recency_df, }\DataTypeTok{on=}\StringTok{"years_since_release"}\NormalTok{)}

\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{rmses=}\NormalTok{years_since_release_lambda, }\DataTypeTok{lambdas =}\NormalTok{ lambdas) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(lambdas, rmses)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{ggtitle}\NormalTok{(}\KeywordTok{paste}\NormalTok{(}\StringTok{"Best RMSE:"}\NormalTok{, }\KeywordTok{round}\NormalTok{(}\KeywordTok{min}\NormalTok{(years_since_release_lambda),}\DecValTok{6}\NormalTok{), }\StringTok{" | Best Lambda:"}\NormalTok{, lambdas[}\KeywordTok{which.min}\NormalTok{(years_since_release_lambda)]))}
\end{Highlighting}
\end{Shaded}

\includegraphics{MovieLens_files/figure-latex/unnamed-chunk-19-1.pdf}

Each additional bias improves our score, but we seem to be approaching
the limit. Now that we've tuned our lambda parameters, we can combine
our different effects and test our model on our validation set. The
lambda parameters to that will be used for each effect are:

\begin{verbatim}
## [1] "Movie Lambda: 2.5"      "Users Lambda: 4.5"      "User Genres Lambda: 15"
## [4] "Recency Lambda: 20"
\end{verbatim}

These four optimal lambda parameters will now be used to separately
calculate movie, user, user-genre, and recency biases for our entire
training set. We will then use those biases to make ratings predictions
for the unseen movie ratings in our validation set. The formula for our
prediction is simply:

\emph{predicted rating = user\_bias + movie\_bias + user\_genre\_bias +
recency\_bias + mu}.

\hypertarget{model-performance-on-validation-set-rmse-0.85355}{%
\paragraph{Model Performance On Validation Set (RMSE):
0.85355}\label{model-performance-on-validation-set-rmse-0.85355}}

\hypertarget{conclusion}{%
\subsection{Conclusion}\label{conclusion}}

To showcase the performance of our model, we can observe a random
selection of ratings from the validation set and compare our predicted
rating against the true rating that was given.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{results_sample <-}\StringTok{ }\NormalTok{validation[}\KeywordTok{sample}\NormalTok{(.N, }\DecValTok{20}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{prediction =} \KeywordTok{round}\NormalTok{(pred }\OperatorTok{/}\StringTok{ }\FloatTok{.5}\NormalTok{) }\OperatorTok{*}\NormalTok{.}\DecValTok{5}\NormalTok{)}
\KeywordTok{print}\NormalTok{(results_sample) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(userId, title, rating, prediction)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     userId movieId rating  timestamp                                      title
##  1:  53607   45730    1.0 1153961170                   Lady in the Water (2006)
##  2:  12239     242    3.5 1138203483              Farinelli: il castrato (1994)
##  3:  59659    3394    2.0  975536776                          Blind Date (1987)
##  4:  15567    1371    3.0 1092336107       Star Trek: The Motion Picture (1979)
##  5:  67615    1573    2.0  980720161                            Face/Off (1997)
##  6:  29979    1676    3.0  889041043                   Starship Troopers (1997)
##  7:  14145    1073    3.0  948376829 Willy Wonka & the Chocolate Factory (1971)
##  8:  71055    3526    3.0 1121537995                          Parenthood (1989)
##  9:  19284    3328    4.5 1094271431   Ghost Dog: The Way of the Samurai (1999)
## 10:   3035     593    5.0  844638018           Silence of the Lambs, The (1991)
## 11:  55707     595    3.0  848223040                Beauty and the Beast (1991)
## 12:  52307    2028    5.0 1092194499                 Saving Private Ryan (1998)
## 13:  18602    2367    3.5 1140030420                           King Kong (1976)
## 14:  19564    1438    5.0  944081112                        Dante's Peak (1997)
## 15:  46694    2247    3.0 1076378325                  Married to the Mob (1988)
## 16:  35537    2380    3.0  954386961  Police Academy 3: Back in Training (1986)
## 17:  66167    4720    4.0 1080676743                         Others, The (2001)
## 18:  16487     916    5.0 1005170316                       Roman Holiday (1953)
## 19:  46732     423    4.0  967403536                          Blown Away (1994)
## 20:  66387     457    4.0  832545352                       Fugitive, The (1993)
##                                         genres release_year rating_year
##  1:                      Drama|Fantasy|Mystery         2006        2006
##  2:                              Drama|Musical         1994        2006
##  3:                             Comedy|Romance         1987        2000
##  4:                           Adventure|Sci-Fi         1979        2004
##  5:                Action|Crime|Drama|Thriller         1997        2001
##  6:                          Action|Sci-Fi|War         1997        1998
##  7:            Children|Comedy|Fantasy|Musical         1971        2000
##  8:                               Comedy|Drama         1989        2005
##  9:                                Crime|Drama         1999        2004
## 10:                      Crime|Horror|Thriller         1991        1996
## 11: Animation|Children|Fantasy|Musical|Romance         1991        1996
## 12:                           Action|Drama|War         1998        2004
## 13:                    Action|Adventure|Horror         1976        2006
## 14:                            Action|Thriller         1997        1999
## 15:                                     Comedy         1988        2004
## 16:                                     Comedy         1986        2000
## 17:                    Horror|Mystery|Thriller         2001        2004
## 18:                             Comedy|Romance         1953        2001
## 19:                            Action|Thriller         1994        2000
## 20:                                   Thriller         1993        1996
##     years_since_release movie_bias   user_bias recency_bias      Comedy
##  1:                   0 -0.6051960  0.05963031  0.007135396  0.00000000
##  2:                  10 -0.1097144 -0.15343681 -0.024534588  0.00000000
##  3:                  15 -0.9030535 -0.68634549  0.008298949  0.08603061
##  4:                  25 -0.4659681 -0.20516511  0.022227462  0.00000000
##  5:                   5 -0.1690525 -0.33697119 -0.015109220  0.00000000
##  6:                   0 -0.3195301  0.19286076  0.007135396  0.00000000
##  7:                  30  0.1951372 -0.38279262  0.021446866  0.09674561
##  8:                  15  0.1097540 -0.76370275  0.008298949 -0.03287916
##  9:                   5  0.2092450 -0.03040053 -0.015109220  0.00000000
## 10:                   5  0.6915790  0.75167469 -0.015109220  0.00000000
## 11:                   5  0.1613021 -0.06723671 -0.015109220  0.00000000
## 12:                   5  0.5713547  0.49750689 -0.015109220  0.00000000
## 13:                  30 -0.7348006  0.43329721  0.021446866  0.00000000
## 14:                   0 -0.6988969  0.14743780  0.007135396  0.00000000
## 15:                  15 -0.3906737 -0.18930483  0.008298949  0.14534344
## 16:                  15 -1.4256713 -0.25620100  0.008298949 -0.00300620
## 17:                   5  0.2017180 -0.37103870 -0.015109220  0.00000000
## 18:                  50  0.6035963 -0.48093348  0.027651948  0.18351905
## 19:                   5 -0.4805593  0.32084980 -0.015109220  0.00000000
## 20:                   5  0.4966416 -0.06104481 -0.015109220  0.00000000
##          Action Adventure     Sci-Fi   Thriller   Children       Drama
##  1:  0.00000000 0.0000000  0.0000000 0.00000000 0.00000000 -0.01169268
##  2:  0.00000000 0.0000000  0.0000000 0.00000000 0.00000000  0.12589933
##  3:  0.00000000 0.0000000  0.0000000 0.00000000 0.00000000  0.00000000
##  4:  0.00000000 0.2706732  0.1457335 0.00000000 0.00000000  0.00000000
##  5:  0.24304724 0.0000000  0.0000000 0.10907433 0.00000000 -0.11403662
##  6: -0.32474265 0.0000000 -0.2280350 0.00000000 0.00000000  0.00000000
##  7:  0.00000000 0.0000000  0.0000000 0.00000000 0.05517157  0.00000000
##  8:  0.00000000 0.0000000  0.0000000 0.00000000 0.00000000  0.07131266
##  9:  0.00000000 0.0000000  0.0000000 0.00000000 0.00000000  0.17339937
## 10:  0.00000000 0.0000000  0.0000000 0.08517685 0.00000000  0.00000000
## 11:  0.00000000 0.0000000  0.0000000 0.00000000 0.00384302  0.00000000
## 12: -0.09144365 0.0000000  0.0000000 0.00000000 0.00000000  0.15564446
## 13:  0.15265964 0.1215043  0.0000000 0.00000000 0.00000000  0.00000000
## 14: -0.39625531 0.0000000  0.0000000 0.05401941 0.00000000  0.00000000
## 15:  0.00000000 0.0000000  0.0000000 0.00000000 0.00000000  0.00000000
## 16:  0.00000000 0.0000000  0.0000000 0.00000000 0.00000000  0.00000000
## 17:  0.00000000 0.0000000  0.0000000 0.03839868 0.00000000  0.00000000
## 18:  0.00000000 0.0000000  0.0000000 0.00000000 0.00000000  0.00000000
## 19:  0.10862213 0.0000000  0.0000000 0.14029950 0.00000000  0.00000000
## 20:  0.00000000 0.0000000  0.0000000 0.09485584 0.00000000  0.00000000
##          Romance         War       Crime    Horror Western    Mystery
##  1:  0.000000000  0.00000000  0.00000000 0.0000000       0 0.11749498
##  2:  0.000000000  0.00000000  0.00000000 0.0000000       0 0.00000000
##  3: -0.013154035  0.00000000  0.00000000 0.0000000       0 0.00000000
##  4:  0.000000000  0.00000000  0.00000000 0.0000000       0 0.00000000
##  5:  0.000000000  0.00000000 -0.10873642 0.0000000       0 0.00000000
##  6:  0.000000000  0.18953702  0.00000000 0.0000000       0 0.00000000
##  7:  0.000000000  0.00000000  0.00000000 0.0000000       0 0.00000000
##  8:  0.000000000  0.00000000  0.00000000 0.0000000       0 0.00000000
##  9:  0.000000000  0.00000000  0.14240786 0.0000000       0 0.00000000
## 10:  0.000000000  0.00000000  0.08323489 0.0000000       0 0.00000000
## 11:  0.115368113  0.00000000  0.00000000 0.0000000       0 0.00000000
## 12:  0.000000000 -0.02255529  0.00000000 0.0000000       0 0.00000000
## 13:  0.000000000  0.00000000  0.00000000 0.2705723       0 0.00000000
## 14:  0.000000000  0.00000000  0.00000000 0.0000000       0 0.00000000
## 15:  0.000000000  0.00000000  0.00000000 0.0000000       0 0.00000000
## 16:  0.000000000  0.00000000  0.00000000 0.0000000       0 0.00000000
## 17:  0.000000000  0.00000000  0.00000000 0.1472524       0 0.06796146
## 18: -0.004329472  0.00000000  0.00000000 0.0000000       0 0.00000000
## 19:  0.000000000  0.00000000  0.00000000 0.0000000       0 0.00000000
## 20:  0.000000000  0.00000000  0.00000000 0.0000000       0 0.00000000
##        Fantasy     Musical Film-Noir    Animation Documentary IMAX
##  1: 0.03838426  0.00000000         0  0.000000000           0    0
##  2: 0.00000000  0.06845630         0  0.000000000           0    0
##  3: 0.00000000  0.00000000         0  0.000000000           0    0
##  4: 0.00000000  0.00000000         0  0.000000000           0    0
##  5: 0.00000000  0.00000000         0  0.000000000           0    0
##  6: 0.00000000  0.00000000         0  0.000000000           0    0
##  7: 0.02403376 -0.11015926         0  0.000000000           0    0
##  8: 0.00000000  0.00000000         0  0.000000000           0    0
##  9: 0.00000000  0.00000000         0  0.000000000           0    0
## 10: 0.00000000  0.00000000         0  0.000000000           0    0
## 11: 0.04212710 -0.01683289         0 -0.008139799           0    0
## 12: 0.00000000  0.00000000         0  0.000000000           0    0
## 13: 0.00000000  0.00000000         0  0.000000000           0    0
## 14: 0.00000000  0.00000000         0  0.000000000           0    0
## 15: 0.00000000  0.00000000         0  0.000000000           0    0
## 16: 0.00000000  0.00000000         0  0.000000000           0    0
## 17: 0.00000000  0.00000000         0  0.000000000           0    0
## 18: 0.00000000  0.00000000         0  0.000000000           0    0
## 19: 0.00000000  0.00000000         0  0.000000000           0    0
## 20: 0.00000000  0.00000000         0  0.000000000           0    0
##     user_genre_bias     pred prediction
##  1:     0.037830488 3.011865        3.0
##  2:     0.056607014 3.281386        3.5
##  3:     0.027058508 1.958424        2.0
##  4:     0.146211387 3.009771        3.0
##  5:     0.022847862 3.014180        3.0
##  6:    -0.089026297 3.303905        3.5
##  7:     0.017447710 3.363704        3.5
##  8:     0.015577483 2.882393        3.0
##  9:     0.100232670 3.776433        4.0
## 10:     0.051100840 4.991711        5.0
## 11:     0.020209387 3.611631        3.5
## 12:     0.006634074 4.572852        4.5
## 13:     0.141545758 3.373954        3.5
## 14:    -0.111700168 2.856441        3.0
## 15:     0.076821195 3.017607        3.0
## 16:     0.002646375 1.841538        2.0
## 17:     0.059625844 3.387661        3.5
## 18:     0.068947175 3.731727        3.5
## 19:     0.077937469 3.415584        3.5
## 20:     0.039873308 3.972826        4.0
\end{verbatim}

\begin{verbatim}
##     userId                                      title rating prediction
##  1:  53607                   Lady in the Water (2006)    1.0        3.0
##  2:  12239              Farinelli: il castrato (1994)    3.5        3.5
##  3:  59659                          Blind Date (1987)    2.0        2.0
##  4:  15567       Star Trek: The Motion Picture (1979)    3.0        3.0
##  5:  67615                            Face/Off (1997)    2.0        3.0
##  6:  29979                   Starship Troopers (1997)    3.0        3.5
##  7:  14145 Willy Wonka & the Chocolate Factory (1971)    3.0        3.5
##  8:  71055                          Parenthood (1989)    3.0        3.0
##  9:  19284   Ghost Dog: The Way of the Samurai (1999)    4.5        4.0
## 10:   3035           Silence of the Lambs, The (1991)    5.0        5.0
## 11:  55707                Beauty and the Beast (1991)    3.0        3.5
## 12:  52307                 Saving Private Ryan (1998)    5.0        4.5
## 13:  18602                           King Kong (1976)    3.5        3.5
## 14:  19564                        Dante's Peak (1997)    5.0        3.0
## 15:  46694                  Married to the Mob (1988)    3.0        3.0
## 16:  35537  Police Academy 3: Back in Training (1986)    3.0        2.0
## 17:  66167                         Others, The (2001)    4.0        3.5
## 18:  16487                       Roman Holiday (1953)    5.0        3.5
## 19:  46732                          Blown Away (1994)    4.0        3.5
## 20:  66387                       Fugitive, The (1993)    4.0        4.0
\end{verbatim}

Overall, the model performs very well against the validation set and
with relatively few predictors. While we were successful in achieving
our goal of a residual mean error (RMSE) \textless{} 0.86490, the author
would like to point out that, even when only applying cross-validation
on approximately 10\% of the training set, it takes a very long time for
the model to run. It likely will not scale well against larger datasets.

Having to calculate the \emph{user\_genre\_bias} for every user/genre
combination by breaking the training and validation sets into their
individual genres only to reassemble them back into a single movie
rating likely contributed the most to the slow performance of this
model. While it was very effective in reducing RMSE, refactoring the way
that this bias is calculated could very well improve the scalability of
our model.

\end{document}
